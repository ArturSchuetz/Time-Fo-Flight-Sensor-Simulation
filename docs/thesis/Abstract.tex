\documentclass[thesis.tex]{subfiles}
\begin{document}

\addchap{Kurzzusammenfassung}

Bei der Simulation von Time-of-Flight Sensoren handelt es sich um ein komplexes Problem, das hohe Anforderungen an die physikalische Plausibilität stellt. Bei der physikalsich plausiblen Berechnung der Lichtausbreitung handelt es sich um ein eingehend erforschtes Feld, das bisher nur selten in der Simulation von Time-of-Flight Sensoren Berücksichtigung fand. Die akkurate Berechnung direkter und indirekter Beleuchtung wurde zum Standard nicht-interaktiver Anwendungen, die beispielsweise beim Rendering von Filmen eingesetzt werden, während Time-of-Flight Sensor Simulationen bisheriger Arbeiten zugunsten der Reduktion der Berechnungszeit auf die korrekte Berechnung der Tiefenwerte verzichteten. Die Implementierung von Algorithmen auf der GPU bietet die Möglichkeit, Verfahren, die bisher in nicht-interaktiven Anwendungen verwendet werden, parallel auf tausenden von Kernen ausführen zu lassen, wobei die Berechnungszeit verkürzt wird, sodass diese Methoden auch in interaktiven Anwendungen genutzt werden können. Dies schlägt die Brücke zwischen physikalisch plausibler Berechnung der Lichtausbreitung und Echtzeitanwendungen, die bisher auf die korrekte Berechnung indirekter Beleuchtung verzichteten.

In dieser Arbeit wird ein Time-of-Flight Sensor präsentiert, der mittels OptiX auf der GPU implementiert wurde und die Lichtausbreitung physikalisch plausibel simuliert. Dabei wird ein Path Tracing Algorithmus genutzt, der auf der GPU parallelisiert wurde und somit deutlich kürzere Berechnungszeiten ermöglicht, während die Berechnung von indirekter Beleuchtung und eine akkurate Simulation der Oberflächen wie in nicht-interaktiven Anwendungen durchgeführt wird. Dazu ist keine Vorberechnung notwendig, weshalb die Parameter der Kamera und der simulierten Umgebung zur Laufzeit der Applikation angepasst werden können. Dazu wird die Berechnung der Simulation progrssiv durchgeführt, sodass der Nutzer ein Feedback über die Zwischenergebnisse erhält und bereits vor der abschließenden Simulation der Szene das mögliche Ergebnis beurteilen und Anpassungen vornehmen kann.

Diese Arbeit führt den Leser in die Theorie der globalen Beleuchtung und die interne Funktionsweise von Time-of-Flight Sensoren ein und stellt eine ausführliche Analyse der Fehler verschiedener Sensoren vor, die im Anschluss in einer Simulation nachgebildet werden. Die abschließende Evaluation vergleicht die Simulation mit der Kinect v2 und zeigt Übereinstimmungen der simulierten Tiefenwerte mit denen der echten Time-of-Flight Kamera Systeme. Verbesserungen können besonders in der Reduktion der Berechnungszeit der Oberflächensimulation durchgeführt werden, da diese Arbeit den Fokus auf eine möglichst korrekte Simulation der Beleuchtung legt.

\end{document}
